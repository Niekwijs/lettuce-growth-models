{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# tf imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loading images with labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = open(\".\\data\\measurements.json\")\n",
    "data_json = json.loads(f.read())[\"Measurements\"]\n",
    "\n",
    "vs = data_json.values()\n",
    "\n",
    "df = pd.json_normalize(vs)\n",
    "\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sort_values(\"Height\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing images shaping\n",
    "img = cv2.imread('.\\data\\RGBImages\\RGB_270.png')\n",
    "w, h, c = img.shape\n",
    "\n",
    "img = img[ (w // 2 - 400 ) : (w // 2 + 400) , (h // 2 - 400 + 100)  : (h // 2 + 400 + 100) ]\n",
    "plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "path = './data/DepthImages/'\n",
    "all_images = []\n",
    "y = []\n",
    "for image_path in os.listdir(path):\n",
    "    y.append(df.loc[df['Depth_Information'] == image_path].Height.item())\n",
    "    img = cv2.imread(path + image_path, -1)\n",
    "    img = img[ (w // 2 - 400 ) : (w // 2 + 400) , (h // 2 - 400 + 100)  : (h // 2 + 400 + 100) ]\n",
    "    img = cv2.resize(img, (250, 250))\n",
    "    all_images.append(img)\n",
    "print(y)\n",
    "X = np.array(all_images)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(800, 800, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[r2_keras])\n",
    "model.summary()\n",
    "# mean squared error\n",
    "# mean absolute error percentage\n",
    "# r2 score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'][4 : ])\n",
    "plt.plot(history.history['val_loss'][4: ])\n",
    "plt.title('model MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.predict([X_train[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ResNet Implementation for regression: depth images height\n",
    "\n",
    "https://towardsdatascience.com/building-a-resnet-in-keras-e8f1322a49ba\n",
    "\n",
    "!!LET OP NIET RUNNEN ZONDER GPU!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=(1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_res_net(input_shape, regression):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters = 64\n",
    "\n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(t)\n",
    "    t = relu_bn(t)\n",
    "\n",
    "    num_blocks_list = [2, 5, 5, 2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j == 0 and i != 0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "\n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    outputs = Dense(19, activation='softmax')(t)\n",
    "\n",
    "    if regression:\n",
    "        outputs = Dense(1, activation='linear')(t)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    if regression:\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mean_absolute_percentage_error']\n",
    "        )\n",
    "    else:\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rn = create_res_net((250,250,1),True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rn.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "timestr = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "name = 'res_net_depth'+timestr\n",
    "\n",
    "checkpoint_path = \"checkpoints/\"+name+\"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.system('mkdir {}'.format(checkpoint_dir))\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1\n",
    ")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=f'tensorboard_logs/{name}',\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "print(X_train.get_shape())\n",
    "rn.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=16,\n",
    "    callbacks=[cp_callback, tensorboard_callback]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rn.predict([X_test[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}