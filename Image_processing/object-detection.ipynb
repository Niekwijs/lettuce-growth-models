{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import sklearn\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# tf imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def depth_image_to_grayscale(img_path):\n",
    "    depth_image = iio.imread(img_path)\n",
    "    depth_instensity = np.array(256 * depth_image / 0x0fff,dtype=np.uint8)\n",
    "    iio.imwrite('../data/GrayScaleImages/grayscale_1.png', depth_instensity)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "depth_image_to_grayscale(\"..\\data\\RGBImages\\RGB_268.png\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[223 221 209]\n",
      "  [222 220 208]\n",
      "  [222 220 208]\n",
      "  ...\n",
      "  [138 129 111]\n",
      "  [135 128 110]\n",
      "  [135 128 110]]\n",
      "\n",
      " [[222 220 208]\n",
      "  [222 220 208]\n",
      "  [222 220 208]\n",
      "  ...\n",
      "  [138 130 109]\n",
      "  [135 129 108]\n",
      "  [135 129 108]]\n",
      "\n",
      " [[222 219 209]\n",
      "  [221 218 208]\n",
      "  [220 217 207]\n",
      "  ...\n",
      "  [136 130 109]\n",
      "  [135 129 108]\n",
      "  [135 129 108]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[151 170 164]\n",
      "  [151 170 164]\n",
      "  [147 166 160]\n",
      "  ...\n",
      "  [ 64  72  60]\n",
      "  [ 65  73  61]\n",
      "  [ 66  74  62]]\n",
      "\n",
      " [[151 170 164]\n",
      "  [150 169 163]\n",
      "  [147 166 160]\n",
      "  ...\n",
      "  [ 64  72  60]\n",
      "  [ 65  73  61]\n",
      "  [ 66  74  62]]\n",
      "\n",
      " [[151 170 164]\n",
      "  [150 169 163]\n",
      "  [147 166 160]\n",
      "  ...\n",
      "  [ 65  73  61]\n",
      "  [ 66  74  62]\n",
      "  [ 68  76  64]]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"..\\data\\RGBImages\\RGB_268.png\")\n",
    "print(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "\n",
    "# RGB images are to dirty to use threshold and grayscale\n",
    "\n",
    "img = cv2.imread('..\\data\\RGBImages\\RGB_268.png')\n",
    "\n",
    "# image resize and down-size to focus on object\n",
    "w, h, c = img.shape\n",
    "img = img[ (w // 2 - 500 ) : (w // 2 + 500) , (h // 2 - 500 + 100)  : (h // 2 + 500 + 100) ]\n",
    "rsz_img = cv2.resize(img, None, fx=0.50, fy=0.50)\n",
    "# concert image from RGB to Grayscale\n",
    "gray = cv2.cvtColor(rsz_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold fine-tuning\n",
    "retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "cv2.imshow(\"resized gray\", thresh_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# # find where the signature is and make a cropped region\n",
    "points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "# points\n",
    "# x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
    "# x, y, w, h = x-10, y-10, w+20, h+20 # make the box a little bigger\n",
    "# crop = gray[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "#\n",
    "# # get the thresholded crop\n",
    "# retval, thresh_crop = cv2.threshold(crop, thresh=200, maxval=255, type=cv2.THRESH_BINARY)\n",
    "#\n",
    "# # display\n",
    "# cv2.imshow(\"Cropped and thresholded image\", thresh_crop)\n",
    "# cv2.waitKey(0)\n",
    "#\n",
    "# cv2.imwrite('Prop_268.png', thresh_crop)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape depth: (1080, 1920)\n",
      "Image shape RGB: (1080, 1920, 3)\n",
      "1390\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[  8,   0],\n       [  9,   0],\n       [  8,   3],\n       ...,\n       [266, 482],\n       [267, 482],\n       [281, 482]], dtype=int64)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# get object region by using threshold and depth images\n",
    "\n",
    "\n",
    "# load images\n",
    "img_depth = cv2.imread(\"..\\data\\DepthImages\\Depth_150.png\", -1)\n",
    "# also providing the RGB image because depth image can't really be seen\n",
    "img_rgb = cv2.imread(\"..\\data\\RGBImages\\RGB_150.png\")\n",
    "\n",
    "# check if both images have the same shape and size, channels don't matter\n",
    "print(f\"Image shape depth: {img_depth.shape}\")\n",
    "print(f\"Image shape RGB: {img_rgb.shape}\")\n",
    "\n",
    "w, h, c = img_rgb.shape\n",
    "# cropping\n",
    "img_rgb = img_rgb[ (w // 2 - 500 ) : (w // 2 + 500) , (h // 2 - 500 + 100)  : (h // 2 + 500 + 100) ]\n",
    "img_depth = img_depth[ (w // 2 - 500 ) : (w // 2 + 500) , (h // 2 - 500 + 100)  : (h // 2 + 500 + 100) ]\n",
    "# zoom\n",
    "img_rgb = cv2.resize(img_rgb, None, fx=0.50, fy=0.50)\n",
    "img_depth = cv2.resize(img_depth, None, fx=0.50, fy=0.50)\n",
    "\n",
    "print(np.amax(img_depth))\n",
    "\n",
    "# finding signature of the depth image and propose a region\n",
    "## filling o with 1 because of some argwhere errors\n",
    "img_depth[img_depth == 0 ] += 1390\n",
    "points = np.argwhere(img_depth < 830) # find where the black pixels are\n",
    "points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "\n",
    "points\n",
    "\n",
    "#\n",
    "# rsz_img = cv2.resize(img, None, fx=0.50, fy=0.50)\n",
    "# # concert image from RGB to Grayscale\n",
    "# gray = cv2.cvtColor(rsz_img, cv2.COLOR_BGR2GRAY)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}